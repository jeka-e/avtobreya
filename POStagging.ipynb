{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я отправила свои **данные** в **МГУ** и в итоге поступила на радость **матери**. Мать на прощание подарила мне золотого слоника на удачу со словами: \"Почаще **три** ему нос и тебе повезет\".\n",
    "В **общаге** меня поселили к трем старшекурсницам с **матфака**. На первый же вечер они **стали** **печь** **жаркое**, одна из них **пила** **Киндзмараули**. **В течение** вечера мы сидели на кухне. Оказывается, мои соседки были **амбидекстры**. Для меня это было **пленительно** и **ново**. На утро **заспанные** соседки пошли на пары. Я проспала и **бегом** собиралась в университет, **пища** от страха опоздать на первую лекцию. **Идя** в аудиторию, я переживала и боялась опозориться перед однокурсниками. \n",
    "\n",
    "Я вставила несколько случаев грамматической омонимии (стали, печь, пленительно и тд), несколько субстантивированных прилагательных (данные, жаркое), аббревиатуру и сокращение (МГУ, матфак), нечастотное слово, название и сленговое слово (амбидекстры, Киндзмараули, общаге), нечастотные части речи (заспанные, пища), а также слова, которые выглядят странно (идя, ново)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_POS_rus = ['PRON', 'VERB', 'PRON', 'NOUN', 'PREP', 'NOUN', 'CONJ', 'PREP', 'NOUN', 'VERB', 'PREP', 'NOUN', 'NOUN', 'NOUN', 'PREP', 'NOUN', 'VERB', 'PRON', 'ADJ', 'NOUN', 'PREP', 'NOUN', 'PREP', 'NOUN', 'ADVB', 'VERB', 'PRON', 'NOUN', 'CONJ','PRON', 'VERB','PREP','NOUN', 'PRON','VERB','PREP','NUMR','NOUN','PREP','NOUN','PREP','NUMR','PRCL','NOUN','PRON','VERB','VERB','NOUN', 'NUMR', 'PREP','PRON','VERB','NOUN','PREP', 'NOUN', 'NOUN', 'PRON', 'VERB','PREP','NOUN', 'PRCL', 'PRON','NOUN','VERB','NOUN','PREP','PRON','PRON','VERB','ADJ', 'CONJ','ADJ', 'PREP','NOUN','PRTF','NOUN','VERB','PREP','NOUN','PRON','VERB','CONJ','ADVB','VERB','PREP','NOUN','GRND','PREP','NOUN','VERB','PREP','NUMR','NOUN','GRND','PREP','NOUN','PRON','VERB','CONJ','VERB','VERB','PREP','NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Friendly** **Fran** walked around that body and **left** without **saying** anything. We must look to the **howes** and not just the **whyes**. She requested time to consider the **matter** **during** the consultation **break**. **Talking** with her was not easy. People like that will **fly** their private **jets** regardless. I thought you were a **fly** on the wall. Tom wondered how **fast** Mary could climb a ladder. A man so **fast**, he is nearly invisible. **Dr.** **Shepherd** is **goin** put down his instruments. Such a coordination body could also **address** the cases of **missing** international institutions. The **FBI** sent a **fella** already.\n",
    "\n",
    "Я брала слова с финалями, характерными для определенных частей речи, однако эти слова иной части речи (-ly финаль наречия, однако friendly прилагательное), также вставлены несколько грамматических омонимов (fly, fast), несколько форм на -ing (они либо причастия, либо герундии), аббревиатура (FBI), имена и фамилия, сокращения, сленговые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_POS_en = ['ADJ', 'NOUN', 'VERB', 'PREP', 'DET', 'NOUN', 'CONJ', 'VERB', 'PREP', 'GRND', 'PRON', 'PRON','VERB','VERB','PRCL','DET','NOUN','CONJ','PRCL','ADVB','DET','NOUN','PRON','VERB','NOUN','PRCL','VERB','DET','NOUN','PREP','DET','ADJ','NOUN','GRND','PREP','PRON','VERB','PRCL','ADJ','NOUN','CONJ','DET','VERB','VERB','PRON','ADJ','NOUN','ADVB','PRON','VERB','PRON','VERB','DET','NOUN','PREP','DET','NOUN','NOUN','VERB','CONJ','ADVB','NOUN','VERB','VERB','DET','NOUN','DET','NOUN','ADVB','ADJ','PRON','VERB','ADVB','ADJ','NOUN','NOUN','VERB','VERB','VERB','PREP','PRON','NOUN','DET','DET','ADJ','NOUN','VERB','ADVB','VERB','DET','NOUN','PREP','GRND','ADJ','NOUN','DET','NOUN','VERB','DET','NOUN','ADVB']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rus = 'Я отправила свои данные в МГУ и в итоге поступил на радость матери. Мать на прощание подарила мне золотого слоника на удачу со словами: \"Почаще три ему нос и тебе повезет\". В общаге меня поселили к трем старшекурсницам с матфака. На первый же вечер они стали печь жаркое, одна из них пила Киндзмараули. В течение вечера мы сидели на кухне. Оказывается, мои соседки были амбидекстры. Для меня это было пленительно и ново. На утро заспанные соседки пошли на пары. Я проспала и бегом собиралась в университет, пища от страха опоздать на первую лекцию. Идя в аудиторию, я переживала и боялась опозориться перед однокурсниками.'\n",
    "text_en = 'Friendly Fran walked around that body and left without saying anything. We must look to the howes and not just the whyes. She requested time to consider the matter during the consultation break. Talking with her was not easy. People like that will fly their private jets regardless. I thought you were a fly on the wall. Tom wondered how fast Mary could climb a ladder. A man so fast, he is nearly invisible. Dr. Shepherd is goin put down his instruments. Such a coordination body could also address the cases of missing international institutions. The FBI sent a fella already.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(text):\n",
    "    words = []\n",
    "    fl = 0\n",
    "    text_ = []\n",
    "    for word in text.split():\n",
    "        words.append(word.strip('.,!?:;-\\'\\\"—»«\\n\\t'))\n",
    "        words = [w.lower() for w in words if w.isalpha()]\n",
    "        if fl == 0: \n",
    "            text_ = word.strip('.,!?:;-\\'\\\"—»«\\n\\t')\n",
    "            fl = 1\n",
    "        else:\n",
    "            text_ += ' ' + word.strip('.,!?:;-\\'\\\"—»«\\n\\t')\n",
    "    return words, text_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайморфи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pm(words):\n",
    "    pm_POS = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        pm_POS.append(str(p.tag.POS))\n",
    "    return pm_POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Майстем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ms(words):\n",
    "    ms_POS = []\n",
    "    for word in words:\n",
    "        if m.analyze(word)[0]['analysis']:\n",
    "            k = [l for l in m.analyze(word)[0]['analysis'][0]['gr'] if l.isupper()]\n",
    "            pos = ''\n",
    "            for el in k:\n",
    "                pos += el\n",
    "            ms_POS.append(pos)\n",
    "        else:\n",
    "            ms_POS.append('')\n",
    "    return ms_POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import MorphVocab\n",
    "morph_vocab = MorphVocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nata(words):\n",
    "    nata_POS = []\n",
    "    for word in words:\n",
    "        forms = morph_vocab(word)\n",
    "        k = [l for l in str(forms[0][1]).split(',')[0] if l.isupper()]\n",
    "        pos = ''\n",
    "        for el in k:\n",
    "            pos += el\n",
    "        nata_POS.append(pos)\n",
    "    return nata_POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    spacy_POS = []\n",
    "    for token in doc:\n",
    "        spacy_POS.append(str(token.pos_))\n",
    "    return spacy_POS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня возникли проблемы с установкой, поэтому его я прогоняла в гугл коллабе, код был такой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "\n",
    "pos = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_flair(text):\n",
    "    sent = []\n",
    "    sentence = Sentence(text)\n",
    "    pos.predict(sentence)\n",
    "    sent.append(sentence.to_tagged_string())\n",
    "    regex = re.compile('<(.+?)>')\n",
    "    flair_POS = re.findall(regex, str(f_pos))\n",
    "    return flair_POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Jeka/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nltk(words):\n",
    "    nltk_POS = []\n",
    "    pos = nltk.pos_tag(words_en)\n",
    "    for word in pos:\n",
    "        nltk_POS.append(word[1])\n",
    "    return nltk_POS\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_rus, text_rus = pre(text_rus)\n",
    "words_en, text_en = pre(text_en)\n",
    "pm = parse_pm(words_rus)\n",
    "ms = parse_ms(words_rus)\n",
    "nata = parse_nata(words_rus)\n",
    "spacy = parse_spacy (text_en)\n",
    "#flair = parse_flair(text_en)\n",
    "flair = ['NNP', 'NNP', 'VBD', 'IN', 'DT', 'NN', 'CC', 'VBD', 'IN', 'VBG', 'NN', 'PRP', 'MD', 'VB', 'IN', 'DT', 'NNS', 'CC', 'RB', 'RB', 'DT', 'UH', 'PRP', 'VBD', 'NN', 'TO', 'VB', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'VBG', 'IN', 'PRP', 'VBD', 'RB', 'JJ', 'NNS', 'IN', 'DT', 'MD', 'VB', 'PRP$', 'JJ', 'NNS', 'RB', 'PRP', 'VBD', 'PRP', 'VBD', 'DT', 'NN', 'IN', 'DT', 'NN', 'NNP', 'VBD', 'WRB', 'RB', 'NNP', 'MD', 'VB', 'DT', 'NN', 'DT', 'NN', 'RB', 'RB', 'PRP', 'VBZ', 'RB', 'JJ', 'NNP', 'NNP', 'VBZ', 'NN', 'VBN', 'RP', 'PRP$', 'NNS', 'PDT', 'DT', 'NN', 'NN', 'MD', 'RB', 'VB', 'DT', 'NNS', 'IN', 'VBG', 'JJ', 'NNS', 'DT', 'NNP', 'VBD', 'DT', 'NN', 'RB']\n",
    "nlt = parse_nltk(words_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pos, correct_pos):\n",
    "    tp = 0\n",
    "    l = []\n",
    "    for i in range(len(pos)):\n",
    "        if compare(pos[i], correct_pos[i]) == 1:\n",
    "            tp += 1\n",
    "    return tp/len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(test, cor):\n",
    "    \n",
    "    d = {'NOUN': ['NOUN', 'S', 'NN', 'NNS', 'PROPN', 'NNP'], \n",
    "        'ADJ': ['ADJF', 'A', 'JJ', 'ADJ', 'ADJS'], \n",
    "        'ADVB': ['ADVB', 'ADV', 'RB','COMP'],\n",
    "        'PREP': ['PREP', 'PR', 'ADP', 'IN', 'TO','RP'],\n",
    "        'VERB': ['VERB', 'INFN', 'V', 'VBN', 'VBD', 'VBZ', 'AUX', 'MD','VB'],\n",
    "        '': ['', 'NONE', 'UNKN', 'X'],\n",
    "        'PRCL': ['PRCL', 'PART'],\n",
    "        'NUMR': ['NUMR', 'NUM', 'CD','ANUM'],\n",
    "        'PRON': ['PRON', 'SPRO', 'APRO', 'NPRO', 'PRP$', 'PRP'],\n",
    "        'GRND': ['GRND', 'VBG'],\n",
    "        'PRTF': ['PRTF'],\n",
    "        'CONJ': ['CONJ','CCONJ', 'SCONJ', 'CC', 'WRB'],\n",
    "        'DET': ['DET', 'DT', 'WDT','JJ', 'PDT']}\n",
    "    if test in d[cor]:\n",
    "        answ = 1\n",
    "    else:\n",
    "        answ = 0\n",
    "    return answ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMorphy:  0.8640776699029126\n",
      "MyStem:  0.8349514563106796\n",
      "Natasha:  0.8543689320388349\n",
      "Spacy:  0.8910891089108911\n",
      "Flair:  0.8811881188118812\n",
      "NLTK:  0.8514851485148515\n"
     ]
    }
   ],
   "source": [
    "print ('PyMorphy: ', accuracy(pm, correct_POS_rus))\n",
    "print ('MyStem: ', accuracy(ms, correct_POS_rus))\n",
    "print ('Natasha: ', accuracy(nata, correct_POS_rus))\n",
    "print ('Spacy: ', accuracy(spacy, correct_POS_en))\n",
    "print ('Flair: ', accuracy(flair, correct_POS_en))\n",
    "print ('NLTK: ', accuracy(nlt, correct_POS_en))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
